#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Code to prepare radar observations: 
    1. Collect data in all seasons between 2015-03 and 2016-02
    2. Remove background noises
    3. Standarize
    4. Segement into 256x256 chucks

@author: Yan Xie (yanxieyx@umich.edu)
"""

# load modules
import matplotlib.pyplot as plt
import numpy as np
import netCDF4 as nc
import numpy.ma
import datetime
import matplotlib.cm as cm
import glob
import calendar

filepath = '/your/input/filepath/for/labeled-data/'


def standardize(x, sca_mn, sca_mx):
    # x is the original array to be scaled
    xmin = np.min(x)
    xmax = np.max(x)
    x_sca01 = ( x - xmin) / (xmax - xmin)  # scaled to be within the range [0, 1]
    x_sca = x_sca01 * (sca_mx - sca_mn) + sca_mn  # scaled to be within the range [sca_mn, sca_mx]
    return x_sca, xmin, xmax
    

def inv_standardize(x_sca, xmn, xmx, sca_mn, sca_mx):
    # x_sca is the scaled array to be inverted
    x_sca01 = (x_sca - sca_mn) / (sca_mx - sca_mn)
    x = x_sca01 * (xmx - xmn) + xmn  # array inverted back from the scaled one 
    return x


def display(tabs, rag, data, varstr):
    # Plot the variables for sanity check 
    if varstr == 'Ze':
        colorlabel = 'dBZ'
        colormap = cm.Spectral_r
    elif varstr == 'Vd':
        colorlabel = 'm/s'
        colormap = cm.RdBu_r    
    elif varstr == 'dVd':
        colorlabel = 's^-1'
        colormap = cm.RdBu_r    
    
    date0 = datetime.datetime.utcfromtimestamp(tabs[0])  
    date1 = datetime.datetime.utcfromtimestamp(tabs[1]) 
    timestr0 = '{:4d}'.format(date0.year) + '{:02d}'.format(date0.month) + \
              '{:02d}'.format(date0.day) + '-' + '{:02d}'.format(date0.hour) + ':' + \
                  '{:02d}'.format(date0.minute) + ':' + '{:02d}'.format(date0.second)
    timestr1 = '{:4d}'.format(date1.year) + '{:02d}'.format(date1.month) + \
              '{:02d}'.format(date1.day) + '-' + '{:02d}'.format(date1.hour) + ':' + \
                  '{:02d}'.format(date1.minute) + ':' + '{:02d}'.format(date1.second)
    
    vabs  = np.max(np.abs(data))
    plt.pcolormesh(np.arange(0,data.shape[1]), rag, data, cmap = colormap, vmin = -vabs, vmax =vabs)
    plt.colorbar(label = colorlabel)
    plt.title(varstr + ' from ' + timestr0 + ' to ' + timestr1, fontsize=8)
    plt.xlabel('Time (seconds)', fontsize=9)
    plt.ylabel('Height AGL (km)', fontsize=9) #height above ground level
    plt.yticks(np.arange(2,10,2))    
    
    plt.show()


# Preprocess the radar observations

idxml = []       # index for existence of melting layer: 0-no; 1-yes
idxtini = []     # initial absolute time of each section
idxtend = []     # end absolute time of each section
Zemin = []
Zemax = []
Vdmin = []
Vdmax = []
dVdmin = []
dVdmax = []

flagsec = 0

for iyear in range(2015, 2017):
    if iyear == 2015:
        monlist = np.arange(3,13)
    elif iyear == 2016:
        monlist = np.arange(1,3)
        
    for imon in range(monlist[1], monlist[1]+1):
        # find the day range of specific month
        numday = calendar.monthrange(iyear, imon)[1]
        
        for iday in range(1, numday+1): # range(1, numday+1)
            for ihr in range(0, 24, 6):  
                
                # filename of the outputs generated by ClickCollect
                fname = 'OutputML?_' + '{:4d}'.format(iyear) + '{:02d}'.format(imon)\
                        + '{:02d}'.format(iday) + '_' + '{:02d}'.format(ihr)\
                        + '-' + '{:02d}'.format(ihr+6) + 'hr' + '.nc'
                
                # check if the file exists
                flist = glob.glob( filepath+fname )
                if len(flist) == 1:
                    f = nc.Dataset(flist[0], 'r')
                    # variables
                    time = f.variables['time'][:]                       # seconds since midnight
                    timeabs = f.variables['timeabs'][:]                 # seconds since 1970-01-01 00:00:00
                    rag = f.variables['range'][:]                       # km, range height of KAZR (4th to 265th bin)
                    Ze = f.variables['Ze'][:]                           # dBZ, radar reflectivity
                    Vd = f.variables['Vd'][:]                           # m s^-1, mean doppler velocity (positive towards radar)
                    dVd = f.variables['dVd'][:]                         # s^-1, gradient of mean doppler velocity
                    mask_noise = f.variables['Mask_Noise'][:]              # logical, mask for background noise
                    #mltup = f.variables['MeltLayer_up'][:]                 # km, upper level height of the melting layer
                    #mltlow = f.variables['MeltLayer_low'][:]               # km, lower level height of the melting layer
                    mask_mlt = f.variables['Mask_MeltLayer'][:]            # logical, melting layer mask: 1-yes; 0-no
                    
                    ############# Step 1: Handle NaN values #############
                    # main idea is to mimic a no-cloud scenario #
                    # substitute NaN values in Ze with -60 dBZ
                    # substitute NaN values in Vd with 0 m/s
                    # substitute NaN values in dVd with 0 s^-1
                    Ze[ np.isnan(Ze) ] = -60
                    Vd[ np.isnan(Vd) ] = 0
                    dVd[ np.isnan(dVd) ] = 0
                    
                    ############# Step 2: Standardize Ze/ Vd/ dVd values between -1 and 1 #############
                    Zescaled, Zemn, Zemx = standardize(Ze, -1, 1)
                    
                    Vdscaled, Vdmn, Vdmx = standardize(Vd, -1, 1)
                    
                    dVdscaled, dVdmn, dVdmx = standardize(dVd, -1, 1)
                    
                    ############ Step 3: Resize the images to the power of 2 ############
                    # current shape: 262 * 5847
                    # convert to new shape: 20 * 256 (2^8) * 256 (2^8)
                    # 262 -> 256 crop out the top 6 rows
                    # 5847 -> 20* 256 (each containing ~ 18min of observations) 
                    Zenew = np.zeros((20, 256, 256))
                    Vdnew = np.zeros((20, 256, 256))
                    dVdnew = np.zeros((20, 256, 256))
                    mask_mltnew = np.zeros((20, 256, 256))
                    mltupnew = np.zeros((20, 256))
                    
                    for isec in range(0, 20):
                        Zenew[isec,:,:] = Zescaled[0:256, (isec*256+(isec+1)*34):(isec+1)*256+(isec+1)*34]
                        Vdnew[isec,:,:] = Vdscaled[0:256, (isec*256+(isec+1)*34):(isec+1)*256+(isec+1)*34]
                        dVdnew[isec,:,:] = dVdscaled[0:256, (isec*256+(isec+1)*34):(isec+1)*256+(isec+1)*34]                        
                        mask_mltnew[isec,:,:] = mask_mlt[0:256, (isec*256+(isec+1)*34):(isec+1)*256+(isec+1)*34]
                        
                        if mask_mltnew[isec,:,:].any():  # if there are any 1 in the mask 
                            idxml.append(1)              # label this section with melting layer exists
                        else:
                            idxml.append(0)              # otherwise, label this section without melting layer
                        
                        idxtini.append(timeabs[isec*256+(isec+1)*34])
                        idxtend.append(timeabs[(isec+1)*256+(isec+1)*34])
                        Zemin.append(Zemn)
                        Zemax.append(Zemx)
                        Vdmin.append(Vdmn)
                        Vdmax.append(Vdmx)
                        dVdmin.append(dVdmn)
                        dVdmax.append(dVdmx)                        
                        
                    ############ Step 4: Concatenate all images  ############
                    if flagsec == 0:
                        Zecat = Zenew
                        Vdcat = Vdnew
                        dVdcat = dVdnew
                        maskmlcat = mask_mltnew
                        flagsec = 1
                    elif flagsec == 1:
                        Zecat = np.concatenate((Zecat, Zenew), axis=0)
                        Vdcat = np.concatenate((Vdcat, Vdnew), axis=0)
                        dVdcat = np.concatenate((dVdcat, dVdnew), axis=0)
                        maskmlcat = np.concatenate((maskmlcat, mask_mltnew), axis=0)
                        



########### Step 5: Take all images and flip to double the sample size ############
Zetot = Zecat
Vdtot = Vdcat
dVdtot = dVdcat
maskmltot = maskmlcat

# convert list to array
idxml = np.array(idxml)
idxtini = np.array(idxtini)
idxtend = np.array(idxtend)
Zemin = np.array(Zemin)
Zemax = np.array(Zemax)
Vdmin = np.array(Vdmin)
Vdmax = np.array(Vdmax)
dVdmin = np.array(dVdmin)
dVdmax = np.array(dVdmax)

# combine multiple arrays into one
idxtabs = np.concatenate((idxtini[:,np.newaxis], idxtend[:,np.newaxis]), axis=1)
Zemnmx = np.concatenate((Zemin[:,np.newaxis], Zemax[:,np.newaxis]), axis=1)
Vdmnmx = np.concatenate((Vdmin[:,np.newaxis], Vdmax[:,np.newaxis]), axis=1)
dVdmnmx = np.concatenate((dVdmin[:,np.newaxis], dVdmax[:,np.newaxis]), axis=1)

# flip and concatenate
idxmltot = idxml
idxtabstot = idxtabs
Zemnmxtot = Zemnmx
Vdmnmxtot = Vdmnmx
dVdmnmxtot = dVdmnmx
                   
############ Step 6: save all images into an array of shape (N, X, Y, 4) ###########
# N: total number of images
# X: image width
# Y: image height
# 4: Reflectivity Ze; Doppler velocity Vd; Doppler velocity gradient dVd; mask layers

datatot = np.concatenate((Zetot[:,:,:,np.newaxis], Vdtot[:,:,:,np.newaxis],\
                          dVdtot[:,:,:,np.newaxis], maskmltot[:,:,:,np.newaxis]), axis=3)                    

############ Step 7: save all scaler information into an array of shape (N, 2, 3) ###########
# N: total number of images
# 2: 1st col - min ; 2nd col - max
# 3: Reflectivity Ze; Doppler velocity Vd; Doppler velocity gradient dVd
scalertot = np.concatenate((Zemnmxtot[:,:,np.newaxis], Vdmnmxtot[:,:,np.newaxis],\
                            dVdmnmxtot[:,:,np.newaxis]), axis=2)
                    

                    
# save the data
ragnew = rag.data[0:256]         # obtain data property of the masked array
fnameout_data = 'data_preprocess' + '{:4d}'.format(iyear) + '{:02d}'.format(imon) +'.npy'

with open(filepath +'DataPre/'+ fnameout_data, 'wb') as fout:
    np.save(fout, datatot, allow_pickle=True)
    np.save(fout, idxtabstot, allow_pickle=True)
    np.save(fout, ragnew[:,np.newaxis], allow_pickle=True)
    np.save(fout, idxmltot, allow_pickle=True)
    np.save(fout, scalertot, allow_pickle=True)                      
                                        
                 
                    
                    
                    
                    
                    
                    
                    
                    
                    
                


